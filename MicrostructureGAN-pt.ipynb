{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b365cc-7744-4446-96ce-08d8934eda38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import neptune\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import trange\n",
    "\n",
    "import sys\n",
    "import os\n",
    " \n",
    "import numpy as np\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3baa89-ef58-4df9-b6d9-64f36730ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = neptune.init_run(\n",
    "    project=\"\",\n",
    "    api_token=\"\",\n",
    ")  # your credentials\n",
    "\n",
    "exp[\"sys/tags\"].add([\"MicrostructureGAN\", 'PT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "126579dc-8762-4665-803e-a43691132c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = exp['sys/id'].fetch()\n",
    "\n",
    "os.makedirs(f'saved_images/{exp_id}')\n",
    "os.makedirs(f'checkpoints/{exp_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95e0339-38e6-4cf2-97b6-070524bf7c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define image size\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "img_channels = 1\n",
    "img_shape = (img_channels, img_height, img_width)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "# Define hyperparameters\n",
    "gp_coef = 1.\n",
    "latent_dim = 100\n",
    "lr_d = 1e-4\n",
    "lr_g = 2e-5\n",
    "\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9908ef5-54a1-41b4-bbcb-3ab714aa1a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabeledImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs, labels):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.imgs[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "def prepare_data():\n",
    "    # Load samples and rotate\n",
    "\n",
    "    data_dir = 'training data'\n",
    "\n",
    "    train_imgs = []\n",
    "    train_labels = []\n",
    "    test_imgs = []\n",
    "    test_labels = []\n",
    "    labels = [0.73, 0.72, 0.7, 0.67, 0.66, 0.62, 0.56, 0.51]\n",
    "\n",
    "    for i in range(4, 12):\n",
    "        subset_imgs = []\n",
    "        subset_label = labels[i - 4]\n",
    "        for j in range(1, 6):\n",
    "            img_dir = f'{data_dir}/{i}-{j}'\n",
    "            for img_file in os.listdir(img_dir):\n",
    "                if img_file.startswith('.'): continue\n",
    "                img = PIL.Image.open(f'{img_dir}/{img_file}')\n",
    "                img_90 = img.transpose(PIL.Image.ROTATE_90)\n",
    "                img_180 = img.transpose(PIL.Image.ROTATE_180)\n",
    "                img_270 = img.transpose(PIL.Image.ROTATE_270)\n",
    "                arr = np.asarray(img)\n",
    "                arr_90 = np.asarray(img_90)\n",
    "                arr_180 = np.asarray(img_180)\n",
    "                arr_270 = np.asarray(img_270)\n",
    "                subset_imgs.append(arr)\n",
    "                subset_imgs.append(arr_90)\n",
    "                subset_imgs.append(arr_180)\n",
    "                subset_imgs.append(arr_270)\n",
    "        if i != 9:\n",
    "            train_imgs.append(subset_imgs)\n",
    "            train_labels.append(subset_label * np.ones((len(subset_imgs), 1)))\n",
    "        else:\n",
    "            test_imgs.append(subset_imgs)\n",
    "            test_labels.append(subset_label * np.ones((len(subset_imgs), 1)))\n",
    "\n",
    "    train_imgs = np.array(train_imgs).reshape((1080 * 7, 1, 256, 256)).astype(np.float32)\n",
    "    train_imgs = (train_imgs.astype(np.float32) - 127.5) / 127.5\n",
    "    train_labels = np.array(train_labels).reshape((1080 * 7, 1)).astype(np.float32)\n",
    "    test_imgs = np.array(test_imgs).reshape((1080, 1, 256, 256)).astype(np.float32)\n",
    "    test_imgs = (test_imgs.astype(np.float32) - 127.5) / 127.5\n",
    "    test_labels = np.array(test_labels).reshape((1080, 1)).astype(np.float32)\n",
    "\n",
    "    return train_imgs, train_labels, test_imgs, test_labels\n",
    "\n",
    "    \n",
    "train_imgs, train_labels, test_imgs, test_labels = prepare_data()\n",
    "\n",
    "dataset_train = LabeledImageDataset(train_imgs, train_labels)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_test = LabeledImageDataset(test_imgs, test_labels)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e8d5c6-91ac-4918-ac03-5b3c225642c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9012578a-36de-43b3-92e5-5e98a5218202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channels: int):\n",
    "        super().__init__()\n",
    "        self.skip_conn = nn.Identity()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding='same'),\n",
    "        )\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.leakyrelu(self.block(X) + self.skip_conn(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a8b3f9-7b1d-4a1c-9905-29789e738b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net_noise = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 100 * 8 * 8),\n",
    "            nn.Unflatten(1, (100, 8, 8)),\n",
    "        )\n",
    "        self.net_label = nn.Sequential(\n",
    "            nn.Linear(1, 16 * 8 * 8),\n",
    "            nn.Unflatten(1, (16, 8, 8)),\n",
    "        )\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(116, 64, kernel_size=9, stride=4, padding=3, output_padding=1),\n",
    "            \n",
    "            ResBlock(64),\n",
    "            ResBlock(64),\n",
    "            ResBlock(64),\n",
    "            ResBlock(64),\n",
    "            ResBlock(64),\n",
    "            ResBlock(64),\n",
    "            \n",
    "            nn.Conv2d(64, 256, kernel_size=3, padding='same'),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding='same'),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            \n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=7, stride=2, padding=3, output_padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        \n",
    "            nn.Conv2d(128, 1, kernel_size=11, stride=1, padding='same'),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        self.net_noise.apply(init_weights)\n",
    "        self.net_label.apply(init_weights)\n",
    "        self.net.apply(init_weights)\n",
    "        \n",
    "    def forward(self, noise: torch.Tensor, label: torch.Tensor):\n",
    "        return self.net(torch.hstack([self.net_noise(noise), self.net_label(label)]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bff8fb4e-6e22-4db4-acd6-d05812521224",
   "metadata": {
    "tags": []
   },
   "source": [
    "g = Generator().to(device)\n",
    "print(summary(g, input_data=[torch.rand((32, 100)), torch.ones((32, 1))], depth=4, device=device))\n",
    "del g"
   ]
  },
  {
   "cell_type": "raw",
   "id": "527c12b1-da04-4025-abbb-bd40d92b6974",
   "metadata": {},
   "source": [
    "==========================================================================================\n",
    "Layer (type:depth-idx)                   Output Shape              Param #\n",
    "==========================================================================================\n",
    "Generator                                [32, 1, 256, 256]         --\n",
    "├─Sequential: 1-1                        [32, 100, 8, 8]           --\n",
    "│    └─Linear: 2-1                       [32, 6400]                646,400\n",
    "│    └─Unflatten: 2-2                    [32, 100, 8, 8]           --\n",
    "├─Sequential: 1-2                        [32, 16, 8, 8]            --\n",
    "│    └─Linear: 2-3                       [32, 1024]                2,048\n",
    "│    └─Unflatten: 2-4                    [32, 16, 8, 8]            --\n",
    "├─Sequential: 1-3                        [32, 1, 256, 256]         --\n",
    "│    └─ConvTranspose2d: 2-5              [32, 64, 32, 32]          601,408\n",
    "│    └─ResBlock: 2-6                     [32, 64, 32, 32]          --\n",
    "│    │    └─Sequential: 3-1              [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-1             [32, 64, 32, 32]          36,928\n",
    "│    │    │    └─LeakyReLU: 4-2          [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-3             [32, 64, 32, 32]          36,928\n",
    "│    │    └─Identity: 3-2                [32, 64, 32, 32]          --\n",
    "│    │    └─LeakyReLU: 3-3               [32, 64, 32, 32]          --\n",
    "│    └─ResBlock: 2-7                     [32, 64, 32, 32]          --\n",
    "│    │    └─Sequential: 3-4              [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-4             [32, 64, 32, 32]          36,928\n",
    "│    │    │    └─LeakyReLU: 4-5          [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-6             [32, 64, 32, 32]          36,928\n",
    "│    │    └─Identity: 3-5                [32, 64, 32, 32]          --\n",
    "│    │    └─LeakyReLU: 3-6               [32, 64, 32, 32]          --\n",
    "│    └─ResBlock: 2-8                     [32, 64, 32, 32]          --\n",
    "│    │    └─Sequential: 3-7              [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-7             [32, 64, 32, 32]          36,928\n",
    "│    │    │    └─LeakyReLU: 4-8          [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-9             [32, 64, 32, 32]          36,928\n",
    "│    │    └─Identity: 3-8                [32, 64, 32, 32]          --\n",
    "│    │    └─LeakyReLU: 3-9               [32, 64, 32, 32]          --\n",
    "│    └─ResBlock: 2-9                     [32, 64, 32, 32]          --\n",
    "│    │    └─Sequential: 3-10             [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-10            [32, 64, 32, 32]          36,928\n",
    "│    │    │    └─LeakyReLU: 4-11         [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-12            [32, 64, 32, 32]          36,928\n",
    "│    │    └─Identity: 3-11               [32, 64, 32, 32]          --\n",
    "│    │    └─LeakyReLU: 3-12              [32, 64, 32, 32]          --\n",
    "│    └─ResBlock: 2-10                    [32, 64, 32, 32]          --\n",
    "│    │    └─Sequential: 3-13             [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-13            [32, 64, 32, 32]          36,928\n",
    "│    │    │    └─LeakyReLU: 4-14         [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-15            [32, 64, 32, 32]          36,928\n",
    "│    │    └─Identity: 3-14               [32, 64, 32, 32]          --\n",
    "│    │    └─LeakyReLU: 3-15              [32, 64, 32, 32]          --\n",
    "│    └─ResBlock: 2-11                    [32, 64, 32, 32]          --\n",
    "│    │    └─Sequential: 3-16             [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-16            [32, 64, 32, 32]          36,928\n",
    "│    │    │    └─LeakyReLU: 4-17         [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-18            [32, 64, 32, 32]          36,928\n",
    "│    │    └─Identity: 3-17               [32, 64, 32, 32]          --\n",
    "│    │    └─LeakyReLU: 3-18              [32, 64, 32, 32]          --\n",
    "│    └─Conv2d: 2-12                      [32, 256, 32, 32]         147,712\n",
    "│    └─Upsample: 2-13                    [32, 256, 64, 64]         --\n",
    "│    └─Conv2d: 2-14                      [32, 256, 64, 64]         590,080\n",
    "│    └─Upsample: 2-15                    [32, 256, 128, 128]       --\n",
    "│    └─ConvTranspose2d: 2-16             [32, 128, 256, 256]       1,605,760\n",
    "│    └─LeakyReLU: 2-17                   [32, 128, 256, 256]       --\n",
    "│    └─Conv2d: 2-18                      [32, 1, 256, 256]         15,489\n",
    "│    └─Tanh: 2-19                        [32, 1, 256, 256]         --\n",
    "==========================================================================================\n",
    "Total params: 4,052,033\n",
    "Trainable params: 4,052,033\n",
    "Non-trainable params: 0\n",
    "Total mult-adds (T): 3.52\n",
    "==========================================================================================\n",
    "Input size (MB): 0.01\n",
    "Forward/backward pass size (MB): 2719.81\n",
    "Params size (MB): 16.21\n",
    "Estimated Total Size (MB): 2736.03\n",
    "==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea43cc88-0356-4145-a76d-8d9e73de4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net_img = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.net_label = nn.Sequential(\n",
    "            nn.Linear(1, 64 * 64 * 20),\n",
    "            nn.Unflatten(1, (20, 64, 64)),\n",
    "        )\n",
    "        self.net = nn.Sequential(\n",
    "            # Original version\n",
    "            nn.Conv2d(148, 512, kernel_size=5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding='same'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            ResBlock(64),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(65536, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "        \n",
    "        self.net_img.apply(init_weights)\n",
    "        self.net_label.apply(init_weights)\n",
    "        self.net.apply(init_weights)\n",
    "        \n",
    "              \n",
    "    def forward(self, img: torch.Tensor, label: torch.Tensor):\n",
    "        return self.net(torch.hstack([self.net_img(img), self.net_label(label)]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14acab17-b576-4f6c-804f-47494a56e0fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "d = Discriminator().to(device)\n",
    "print(summary(d, input_data=[torch.rand((32, 1, 256, 256)), torch.ones((32, 1))], depth=4, device=device))\n",
    "del d"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05afe1b1-8500-40fb-bade-b100bb488720",
   "metadata": {},
   "source": [
    "==========================================================================================\n",
    "Layer (type:depth-idx)                   Output Shape              Param #\n",
    "==========================================================================================\n",
    "Discriminator                            [32, 1]                   --\n",
    "├─Sequential: 1-1                        [32, 128, 64, 64]         --\n",
    "│    └─Conv2d: 2-1                       [32, 64, 128, 128]        1,088\n",
    "│    └─LeakyReLU: 2-2                    [32, 64, 128, 128]        --\n",
    "│    └─Conv2d: 2-3                       [32, 128, 64, 64]         131,200\n",
    "│    └─LeakyReLU: 2-4                    [32, 128, 64, 64]         --\n",
    "├─Sequential: 1-2                        [32, 20, 64, 64]          --\n",
    "│    └─Linear: 2-5                       [32, 81920]               163,840\n",
    "│    └─Unflatten: 2-6                    [32, 20, 64, 64]          --\n",
    "├─Sequential: 1-3                        [32, 1]                   --\n",
    "│    └─Conv2d: 2-7                       [32, 512, 32, 32]         1,894,912\n",
    "│    └─LeakyReLU: 2-8                    [32, 512, 32, 32]         --\n",
    "│    └─Conv2d: 2-9                       [32, 256, 32, 32]         1,179,904\n",
    "│    └─LeakyReLU: 2-10                   [32, 256, 32, 32]         --\n",
    "│    └─Conv2d: 2-11                      [32, 128, 32, 32]         295,040\n",
    "│    └─LeakyReLU: 2-12                   [32, 128, 32, 32]         --\n",
    "│    └─Conv2d: 2-13                      [32, 64, 32, 32]          73,792\n",
    "│    └─LeakyReLU: 2-14                   [32, 64, 32, 32]          --\n",
    "│    └─ResBlock: 2-15                    [32, 64, 32, 32]          --\n",
    "│    │    └─Sequential: 3-1              [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-1             [32, 64, 32, 32]          36,928\n",
    "│    │    │    └─LeakyReLU: 4-2          [32, 64, 32, 32]          --\n",
    "│    │    │    └─Conv2d: 4-3             [32, 64, 32, 32]          36,928\n",
    "│    │    └─Identity: 3-2                [32, 64, 32, 32]          --\n",
    "│    │    └─LeakyReLU: 3-3               [32, 64, 32, 32]          --\n",
    "│    └─Flatten: 2-16                     [32, 65536]               --\n",
    "│    └─Linear: 2-17                      [32, 512]                 33,554,944\n",
    "│    └─LeakyReLU: 2-18                   [32, 512]                 --\n",
    "│    └─Linear: 2-19                      [32, 1]                   513\n",
    "==========================================================================================\n",
    "Total params: 37,369,089\n",
    "Trainable params: 37,369,089\n",
    "Non-trainable params: 0\n",
    "Total mult-adds (G): 134.11\n",
    "==========================================================================================\n",
    "Input size (MB): 8.39\n",
    "Forward/backward pass size (MB): 708.97\n",
    "Params size (MB): 149.48\n",
    "Estimated Total Size (MB): 866.83\n",
    "==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16618902-f889-465e-86b8-4a664e34a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_g = Generator().to(device)\n",
    "net_d = Discriminator().to(device)\n",
    "\n",
    "opt_g = torch.optim.Adam(net_g.parameters(), lr=lr_g, betas=(0., .9), eps=1e-07)\n",
    "opt_d = torch.optim.Adam(net_d.parameters(), lr=lr_d, betas=(0., .9), eps=1e-07)\n",
    "\n",
    "def train():\n",
    "    for epoch in trange(500):\n",
    "        for i, batch in enumerate(dataloader_train, 0):\n",
    "            train_step(batch)\n",
    "        if epoch % 5 == 0: visualize(epoch)\n",
    "        if epoch % 50 == 0: checkpoint(epoch)\n",
    "\n",
    "def train_step(batch):\n",
    "    imgs_real, labels = batch\n",
    "    imgs_real = imgs_real.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    batch_size = labels.size()[0]\n",
    "    noises = torch.randn((batch_size, latent_dim), device=device)\n",
    "\n",
    "    train_step_d(imgs_real, labels, noises)\n",
    "    train_step_g(noises, labels)\n",
    "    \n",
    "def train_step_d(imgs_real, labels, noises):\n",
    "    opt_d.zero_grad()\n",
    "\n",
    "    imgs_fake = net_g(noises, labels)\n",
    "    loss_d_real = net_d(imgs_real, labels).mean()\n",
    "    loss_d_fake = net_d(imgs_fake, labels).mean()\n",
    "\n",
    "    grad_penalty = compute_gp(imgs_real, imgs_fake, labels)\n",
    "\n",
    "    loss_d = loss_d_fake - loss_d_real + gp_coef * grad_penalty\n",
    "    loss_d.backward()\n",
    "    \n",
    "    opt_d.step()\n",
    "\n",
    "    exp['loss_d_fake'].append(loss_d_fake)\n",
    "    exp['loss_d_real'].append(loss_d_real)\n",
    "    exp['loss_d'].append(loss_d)\n",
    "    exp['grad_penalty'].append(grad_penalty)\n",
    "    \n",
    "def train_step_g(noises, labels):\n",
    "    opt_g.zero_grad()\n",
    "\n",
    "    imgs_gen = net_g(noises, labels)\n",
    "    \n",
    "    loss_g = -net_d(imgs_gen, labels).mean()\n",
    "    loss_g.backward()\n",
    "    \n",
    "    opt_g.step()\n",
    "\n",
    "    exp['loss_g'].append(loss_g)\n",
    "\n",
    "\n",
    "\n",
    "def compute_gp(imgs_real, imgs_fake, labels):\n",
    "    batch_size = labels.size()[0]\n",
    "\n",
    "    epsilon = torch.rand((batch_size, 1, 1, 1), device=device).expand_as(imgs_real)\n",
    "    imgs_interpolated = epsilon * imgs_real + (1 - epsilon) * imgs_fake\n",
    "    imgs_interpolated.requires_grad_()\n",
    "\n",
    "    logits_interpolated = net_d(imgs_interpolated, labels)\n",
    "    grad_outputs = torch.ones_like(logits_interpolated)\n",
    "\n",
    "    grad_interpolated = torch.autograd.grad(\n",
    "        outputs=logits_interpolated,\n",
    "        inputs=imgs_interpolated,\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0].view(batch_size, -1)\n",
    "\n",
    "    grad_norm = grad_interpolated.norm(2, 1)\n",
    "    grad_penalty = ((grad_norm - 1) ** 2).mean()\n",
    "    \n",
    "    return grad_penalty\n",
    "\n",
    "def visualize(current_epoch):\n",
    "    r = 2\n",
    "    c = 2\n",
    "    noises = torch.rand((1, 100), device=device).repeat((4, 1))\n",
    "    labels = torch.tensor([0.72, 0.7, 0.62, 0.51], device=device).reshape((4, 1))\n",
    "    imgs_gen = net_g(noises, labels) * 127.5 + 127.5\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    idx = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(imgs_gen[idx, 0, :, :].detach().cpu().reshape((256, 256)), cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            idx += 1\n",
    "    exp[\"generated_imgs\"].append(fig, step=current_epoch)\n",
    "    fig.savefig(f'saved_images/{exp_id}/{current_epoch}.png')\n",
    "    plt.close()\n",
    "    \n",
    "def checkpoint(tag):\n",
    "    torch.save([net_g, net_d], f'checkpoints/{exp_id}/{tag}.pt')\n",
    "    exp[f'model_checkpoints/{tag}'].upload(f'checkpoints/{exp_id}/{tag}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c9d2a9-9c38-4042-b3f7-1572b48bd296",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aada8b71b4854763911df89eee92b66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d9030efb4d43f46",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "checkpoint('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec808b3-d9fb-42a6-9b19-98b9b5d71900",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9f95e-36ee-49f8-8fb0-d61dd53f54ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorchLightning",
   "language": "python",
   "name": "ptl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
